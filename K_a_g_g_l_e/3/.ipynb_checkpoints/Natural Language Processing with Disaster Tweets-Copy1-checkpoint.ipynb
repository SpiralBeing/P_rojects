{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.sparse import hstack\n",
    "\n",
    "import sklearn.metrics as metrics\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier  \n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier  \n",
    "from sklearn.svm import SVC \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"nlp-getting-started/train.csv\")\n",
    "df_test = pd.read_csv(\"nlp-getting-started/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
       "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
       "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
       "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
       "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
       "\n",
       "   target  \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  \n",
       "3       1  \n",
       "4       1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7613, 5) (3263, 4)\n"
     ]
    }
   ],
   "source": [
    "display(df_train.head())\n",
    "print(df_train.shape, df_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Our Deeds are the Reason of this #earthquake May ALLAH Forgive us all'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.loc[0,'text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.drop([\"keyword\",\"location\"], axis=1, inplace=True)\n",
    "df_test.drop([\"keyword\",\"location\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                               text  target\n",
       "0   1  Our Deeds are the Reason of this #earthquake M...       1\n",
       "1   4             Forest fire near La Ronge Sask. Canada       1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df_train.head(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check for missing values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id        0\n",
       "text      0\n",
       "target    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    4342\n",
       "1    3271\n",
       "Name: target, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df_train.target.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=green>Не сильная разбалансированность. Оставим все как есть</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pandas(Index=0, id=1, text='Our Deeds are the Reason of this #earthquake May ALLAH Forgive us all', target=1)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(df_train.itertuples())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detect & remove empty strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 blanks:  []\n"
     ]
    }
   ],
   "source": [
    "blanks = []\n",
    "\n",
    "for index, i, text, target in df_train.itertuples():  # iterate over the DataFrame\n",
    "    if type(text)==str:            # avoid NaN values\n",
    "        if text.isspace():         # test 'review' for whitespace\n",
    "            blanks.append(i) \n",
    "        \n",
    "print(len(blanks), 'blanks: ', blanks)\n",
    "\n",
    "df_train.drop(blanks, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Избавимся от ссылок"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#stormchase Violent Record Breaking EF-5 El Reno Oklahoma Tornado Nearly Runs Over ... - http://t.co/3SICroAaNz http://t.co/I27Oa0HISp\n",
      "['http://t.co/3SICroAaNz', 'http://t.co/I27Oa0HISp']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'#stormchase Violent Record Breaking EF-5 El Reno Oklahoma Tornado Nearly Runs Over ... -  '"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "line = df_train[\"text\"].head(-5).values[-1]\n",
    "print(line)\n",
    "\n",
    "pattern = r'http://[/.\\w]+'#cuz maybe https://... or http://  or just http\n",
    "print(re.findall(pattern, line))\n",
    "\n",
    "re.sub(pattern,'',line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rid_of_link(text):\n",
    "    raw_s = r'{}'.format(text)\n",
    "    pattern = r'http[:/.\\w]+'\n",
    "    raw_s = re.sub(pattern,'',raw_s)\n",
    "    return(raw_s)\n",
    "\n",
    "df_train[\"text\"] = df_train[\"text\"].apply(get_rid_of_link)\n",
    "df_test[\"text\"] = df_test[\"text\"].apply(get_rid_of_link)\n",
    "df_train.to_csv(\"nlp-getting-started/train_without_link.csv\", index=False)\n",
    "df_test.to_csv(\"nlp-getting-started/test_without_link.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Создание features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Find time (am/pm/UTC/..)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['10:34:24', 'UTC', '06:34:24', '4:00']\n",
      "Earthquake : M 3.4 - 96km N of Brenas Puerto Rico: Time2015-08-05  2015-08-05  - atÛ_\n",
      "Earthquake : M 3.4 - 96km N of Brenas Puerto Rico: Time2015-08-05 10:34:24 UTC2015-08-05 06:34:24 -4:00 atÛ_\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "pattern = r\"[\\d]+:[\\d]+:[\\d]+\"\n",
    "pattern_2 = r\"[\\d]+:[\\d]+\"\n",
    "pattern_3 = r\"(am|pm|UTC)\"\n",
    "\n",
    "pattern = r\"[\\d]+:[\\d]+:[\\d]+|[\\d]+:[\\d]+|am|pm|UTC\"\n",
    "\n",
    "line = r\"Earthquake : M 3.4 - 96km N of Brenas Puerto Rico: Time2015-08-05 10:34:24 UTC2015-08-05 06:34:24 -4:00 atÛ_\"\n",
    "print(re.findall(pattern, line))\n",
    "print(re.sub(pattern, \"\",line))\n",
    "print(line)\n",
    "\n",
    "line = r\"Meow, Sparta\"\n",
    "print(re.findall(pattern, line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_bool_time_feature(text):\n",
    "    raw_s = r'{}'.format(text)\n",
    "    pattern = r\"[\\d]+:[\\d]+:[\\d]+|[\\d]+:[\\d]+|am|pm|UTC\"\n",
    "    if(len(re.findall(pattern, raw_s))!=0):\n",
    "        return(1)\n",
    "    else:\n",
    "        return(0)\n",
    "    \n",
    "def get_rid_of_time(text):\n",
    "    raw_s = r'{}'.format(text)\n",
    "    pattern = r\"[\\d]+:[\\d]+:[\\d]+|[\\d]+:[\\d]+|am|pm|UTC\"\n",
    "    raw_s = re.sub(pattern,'',raw_s)\n",
    "    return(raw_s)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train[\"time\"] = df_train[\"text\"].apply(create_bool_time_feature)\n",
    "df_test[\"time\"] = df_test[\"text\"].apply(create_bool_time_feature)\n",
    "\n",
    "df_train[\"text\"] = df_train[\"text\"].apply(get_rid_of_time)\n",
    "df_test[\"text\"] = df_test[\"text\"].apply(get_rid_of_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    5898\n",
       "1    1715\n",
       "Name: time, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[\"time\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Удалим дубликаты \n",
    "Есть дубликаты. Некоторые наблюдения полностью совпадают по \"text\", некоторые отличаются орфографической ошибкой в тексте.  \n",
    "Удалим те, что полностью идентичны по feature \"text\" (значения \"taget\" порой разные)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amount of observations: (7613,),\n",
      "Number of unique observations: (6989,)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Amount of observations: {df_train.text.shape},\\nNumber of unique observations: {df_train.text.unique().shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.drop_duplicates(subset=['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Find Countries, cities, states "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "import spacy\n",
    "nlp = spacy.load('en_core_web_md')#small version\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "def create_bool_GPE(text):\n",
    "    raw_s = nlp(u'{}'.format(text))\n",
    "    GPE_list = [1 for val in raw_s.ents if val.label_==\"GPE\"]\n",
    "    if(len(GPE_list)!=0):\n",
    "        return(1)\n",
    "    else:\n",
    "        return(0)\n",
    "    \n",
    "def get_rid_of_GPE(text):\n",
    "    raw_s = r'{}'.format(text)\n",
    "    raw_s_nlp = nlp(u'{}'.format(text))\n",
    "    GPE_list = [val.text for val in raw_s_nlp.ents if val.label_==\"GPE\"]\n",
    "    for GPE_item in GPE_list:\n",
    "        try:\n",
    "            raw_s = re.sub(GPE_item, '', raw_s)\n",
    "        except:\n",
    "            pass\n",
    "    return(raw_s)\n",
    "\n",
    "\n",
    "\n",
    "doc8 = nlp(u'A Cessna airplane accident in Ocampo Coahuila Mexico on July 29 2015 killed four men including a State of Coahuila government official. Horrible Accident Man Died In Wings of Airplane (29-07-2015)')\n",
    "\n",
    "GPE_list = [val.text for val in doc8.ents if val.label_==\"GPE\"]\n",
    "print(GPE_list)\n",
    "print(doc8)\n",
    "print(get_rid_of_GPE(doc8))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "df_train[\"GPE\"] = df_train[\"text\"].apply(create_bool_GPE)\n",
    "df_test[\"GPE\"] = df_test[\"text\"].apply(create_bool_GPE)\n",
    "\n",
    "df_train[\"text\"] = df_train[\"text\"].apply(get_rid_of_GPE)\n",
    "df_test[\"text\"] = df_test[\"text\"].apply(get_rid_of_GPE)\n",
    "\n",
    "df_train[\"GPE\"].value_counts()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "df_train.to_csv(\"nlp-getting-started/df_train_cleaned.csv\", index=False)\n",
    "df_test.to_csv(\"nlp-getting-started/df_test_cleaned.csv\", index=False)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word dictionary. Отбор признаков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(min_df = 3, max_df = 5000)\n",
    "\n",
    "X_train_counts = vectorizer.fit(df_train[\"text\"])\n",
    "word_freq = X_train_counts.vocabulary_\n",
    "word_freq = dict(sorted(word_freq.items(), key=lambda x: x[1], reverse=True))\n",
    "#word_freq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "word dictionary дал идею о:  \n",
    "- удалении ссылок\n",
    "- cоздании binary features: время (чуть улучшило), дата, город/страна (чуть ухудшило logistic regression)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics Estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metric_score(model): \n",
    "\n",
    "    # Form a prediction set\n",
    "    predictions = model.predict(X_test)\n",
    "    print(metrics.confusion_matrix(y_test,predictions))\n",
    "    \n",
    "    # Print a classification report\n",
    "    print(metrics.classification_report(y_test,predictions))\n",
    "    \n",
    "    # Print the overall accuracy\n",
    "    print(metrics.accuracy_score(y_test,predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split the data into train & test sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_train[['text','time']]#,'GPE']]  # this time we want to look at the text\n",
    "\n",
    "#X = df_train['text']\n",
    "y = df_train['target']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "print(y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = ['.','?','@','+',',','<','>','%','~','!','^','&','(',')',':',';']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(min_df=2, max_df=0.6, stop_words=stopwords)\n",
    "vectorizer = vectorizer.fit(X_train.text)\n",
    "\n",
    "X_train_ = vectorizer.transform(X_train.text) # remember to use the original X_train set\n",
    "X_test_ = vectorizer.transform(X_test.text)\n",
    "\n",
    "#y_train = y_train.reshape(-1, 1)\n",
    "#y_test = y_test.reshape(-1, 1)\n",
    "\n",
    "X_train_.shape# return sparse matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=blue>Words which left in X_train_</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_freq = vectorizer.vocabulary_\n",
    "word_freq = dict(sorted(word_freq.items(), key=lambda x: x[1], reverse=False))\n",
    "print(len(word_freq))\n",
    "word_freq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=blue>Words which was recognized as *stop_words* and hence was deleted. This is result of params inside \"TfidfVectorizer\"</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(vectorizer.stop_words_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "X_train_ = hstack((X_train_, np.array([X_train.time.values]).T))\n",
    "X_test_ = hstack((X_test_, np.array([X_test.time.values]).T))\n",
    "\n",
    "X_train = hstack((X_train_, np.array([X_train.GPE.values]).T))\n",
    "X_test = hstack((X_test_, np.array([X_test.GPE.values]).T))\n",
    "'''\n",
    "\n",
    "X_train = hstack((X_train_, np.array([X_train.time.values]).T))\n",
    "X_test = hstack((X_test_, np.array([X_test.time.values]).T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clf_lr = LogisticRegression()\n",
    "#clf_lr.fit(X_train,y_train)\n",
    "#metric_score(clf_lr)\n",
    "\n",
    "\n",
    "model_list = [\n",
    "             KNeighborsClassifier(n_neighbors=10),\n",
    "             MultinomialNB(),\n",
    "             DecisionTreeClassifier(),\n",
    "    LGBMClassifier(),\n",
    "    RandomForestClassifier(),\n",
    "             SVC(kernel=\"linear\"),\n",
    "             LogisticRegression()]\n",
    "\n",
    "\n",
    "for model in model_list[3:]:\n",
    "    print(f\"--------------\\n{type(model)}\")\n",
    "    model.fit(X_train,y_train)\n",
    "    metric_score(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's try to choose custom threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = clf_lr.predict(X_test)\n",
    "print(predictions[:5])\n",
    "#predict_proba()\n",
    "\n",
    "predictions = clf_lr.predict_proba(X_test)\n",
    "print(predictions[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the fpr and tpr for all thresholds of the classification\n",
    "probs = clf_lr.predict_proba(X_test)\n",
    "preds = probs[:,1]\n",
    "fpr, tpr, threshold = metrics.roc_curve(y_test, preds)\n",
    "roc_auc = metrics.auc(fpr, tpr)\n",
    "\n",
    "# method I: plt\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(x_test, y_test):\n",
    "    threshold_list = list()\n",
    "    sensitivity_list = list()\n",
    "    specificity_list = list()\n",
    "    accuracy_list = list()\n",
    "\n",
    "    probs = clf_lr.predict_proba(x_test)\n",
    "    preds = probs[:,1]\n",
    "    \n",
    "    for threshold in np.arange(0.1,1,0.025):\n",
    "        threshold = round(threshold,2)\n",
    "\n",
    "        test_df = pd.DataFrame(y_test)\n",
    "        test_df[\"predicted\"] = preds\n",
    "\n",
    "        test_df[\"predicted\"] = test_df[\"predicted\"].apply(lambda x: 1 if x >threshold else 0)\n",
    "        CM = confusion_matrix(test_df.target, test_df.predicted)\n",
    "\n",
    "        TN = CM[0][0]\n",
    "        FN = CM[1][0]\n",
    "        TP = CM[1][1]\n",
    "        FP = CM[0][1]\n",
    "\n",
    "        sensitivity = TP/(TP+FN)\n",
    "        specificity = TN/(TN+FP)\n",
    "        accuracy = (TP+TN)/(TP+FP+TN+FN)\n",
    "\n",
    "        threshold_list.append(threshold)\n",
    "        sensitivity_list.append(sensitivity)\n",
    "        specificity_list.append(specificity)\n",
    "        accuracy_list.append(accuracy)\n",
    "    return([threshold_list,sensitivity_list, specificity_list, accuracy_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_curves(x_min, x_max, x_test,y_test):\n",
    "    threshold_list, sensitivity_list, specificity_list, accuracy_list = calculate_metrics(x_test, y_test)\n",
    "    x = threshold_list\n",
    "\n",
    "    fig=plt.figure(figsize=(6,6))\n",
    "    fig.show()\n",
    "    ax=fig.add_subplot(111)\n",
    "\n",
    "    ax.plot(x,sensitivity_list,c='r',label='Sensitivity',fillstyle='none')\n",
    "    ax.plot(x,specificity_list,c='blue',label='Specificity')\n",
    "    ax.plot(x,accuracy_list,c='black',label='Accuracy')\n",
    "\n",
    "    plt.xlim(x_min, x_max)\n",
    "\n",
    "    plt.grid(True)\n",
    "    plt.legend(loc=3)\n",
    "    plt.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_curves(0,1, X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_curves(0.35,0.5, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's train model on the whole training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3936  186]\n",
      " [ 728 2139]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.95      0.90      4122\n",
      "           1       0.92      0.75      0.82      2867\n",
      "\n",
      "    accuracy                           0.87      6989\n",
      "   macro avg       0.88      0.85      0.86      6989\n",
      "weighted avg       0.88      0.87      0.87      6989\n",
      "\n",
      "0.8692230648161396\n"
     ]
    }
   ],
   "source": [
    "X = df_train[['text','time']]#,'GPE']]  # this time we want to look at the text\n",
    "\n",
    "#X = df_train['text']\n",
    "y = df_train['target']\n",
    "\n",
    "stopwords = ['.','?','@','+',',','<','>','%','~','!','^','&','(',')',':',';']\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer(min_df=2, max_df=0.6, stop_words=stopwords)\n",
    "\n",
    "X_train_ = vectorizer.fit_transform(X.text) # remember to use the original X_train set\n",
    "X_train = hstack((X_train_, np.array([X.time.values]).T))\n",
    "clf_lr = LogisticRegression()\n",
    "clf_lr.fit(X_train,y)\n",
    "\n",
    "predictions = clf_lr.predict(X_train)\n",
    "print(metrics.confusion_matrix(y,predictions))\n",
    "# Print a classification report\n",
    "print(metrics.classification_report(y,predictions))\n",
    "# Print the overall accuracy\n",
    "print(metrics.accuracy_score(y,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plot_curves' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-996938792e66>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplot_curves\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'plot_curves' is not defined"
     ]
    }
   ],
   "source": [
    "plot_curves(0,1, X_train, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_curves(.36, .6, X_train, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict and create csv for kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_df = df_test[['text','time']]#,'GPE']]  # this time we want to look at the text\n",
    "\n",
    "X_test_ = vectorizer.transform(X_test_df.text) # remember to use the original X_train set\n",
    "X_test = hstack((X_test_, np.array([X_test_df.time.values]).T))\n",
    "\n",
    "predictions = clf_lr.predict_proba(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test[\"target\"] = predictions[:,1]\n",
    "df_test.drop([\"text\"], axis=1,inplace=True)\n",
    "df_test.drop([\"time\"], axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.654548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.474613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.721908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>0.443755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>0.852724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>12</td>\n",
       "      <td>0.583510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>21</td>\n",
       "      <td>0.216445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>22</td>\n",
       "      <td>0.120387</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id    target\n",
       "0   0  0.654548\n",
       "1   2  0.474613\n",
       "2   3  0.721908\n",
       "3   9  0.443755\n",
       "4  11  0.852724\n",
       "5  12  0.583510\n",
       "6  21  0.216445\n",
       "7  22  0.120387"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.502754    11\n",
       "0.519928    10\n",
       "0.269756    10\n",
       "0.219005     8\n",
       "0.832629     6\n",
       "            ..\n",
       "0.614678     1\n",
       "0.121832     1\n",
       "0.405145     1\n",
       "0.646753     1\n",
       "0.241227     1\n",
       "Name: target, Length: 3039, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display(df_test.head(8))\n",
    "df_test.target.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test[\"target\"] = df_test[\"target\"].apply(lambda x: 1 if x > 0.5 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.to_csv(\"nlp-getting-started/answer.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = ['a', 'about', 'an', 'and', 'are', 'as', 'at', 'be', 'been', 'but', 'by', 'can', \\\n",
    "             'even', 'ever', 'for', 'from', 'get', 'had', 'has', 'have', 'he', 'her', 'hers', 'his', \\\n",
    "             'how', 'i', 'if', 'in', 'into', 'is', 'it', 'its', 'just', 'me', 'my', 'of', 'on', 'or', \\\n",
    "             'see', 'seen', 'she', 'so', 'than', 'that', 'the', 'their', 'there', 'they', 'this', \\\n",
    "             'to', 'was', 'we', 'were', 'what', 'when', 'which', 'who', 'will', 'with', 'you']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "text_clf = Pipeline([('tfidf', TfidfVectorizer(stop_words=None)),\n",
    "                     ('clf', LinearSVC()),\n",
    "])\n",
    "\n",
    "\n",
    "# Naïve Bayes:\n",
    "text_clf_nb = Pipeline([('tfidf', TfidfVectorizer(stop_words=None)),\n",
    "                     ('clf', MultinomialNB()),\n",
    "])\n",
    "\n",
    "text_clf_logistic_regression = Pipeline([('tfidf', TfidfVectorizer(stop_words=None)),\n",
    "                                         ('clf', LogisticRegression()),\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the classifier and display results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_clf.fit(X_train, y_train)  \n",
    "text_clf_nb.fit(X_train, y_train)  \n",
    "text_clf_logistic_regression.fit(X_train, y_train)  \n",
    "\n",
    "models_dict = {\"SVC\": text_clf, \"Naïve Bayes\":text_clf_nb, \n",
    "               \"Logistic_Reg.(threshold=0.5)\":text_clf_logistic_regression}\n",
    "for key, model in models_dict.items():\n",
    "    print(key)\n",
    "    metric_score(model)\n",
    "    print(\"-\"*55)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict values on test dataset & save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions = text_clf.predict(df_test['text'])\n",
    "df_test[\"target\"] = test_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.drop([\"text\"], axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.to_csv(\"nlp-getting-started/answer.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Чтобы попробывать  \n",
    "* EDA:\n",
    "    1. Dict of word frequency\n",
    "    2. Based on 1, calculate p-value for top-N the most/last frequent \n",
    "    \n",
    "\n",
    "\n",
    "* Logistic regression -> useing ROC to determine threshold value (not 0.5 maybe)  \n",
    "\n",
    "\n",
    "* советы с https://machinelearningmastery.com?\n",
    "\n",
    "### Вывод:  \n",
    "Из Dict of word frequency понял, что следует убрать все ссылки  \n",
    "Пример:  `http://t.co/zLvEbEoavG`.  \n",
    "*Ссылки не всегда в конце текста!*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
